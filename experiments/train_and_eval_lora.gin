PEFTTrain.embedder_class = @TrainableEmbedding
    TrainableEmbedding.method='average'
PEFTTrain.loss=@double_loss
PEFTTrain.optimizer_class = @torch.optim.AdamW
    AdamW.weight_decay = 0.1
PEFTTrain.scheduler_class=@WarmupCosineScheduler
PEFTTrain.eval_job_class = @MTEBJob
    MTEBJob.tasks = 'data/mteb/test_tasks_list'
PEFTTrain.learning_rate=0.001
PEFTTrain.checkpointing=True
PEFTTrain.datapath='data/nli/all.jsonl'
PEFTTrain.eval_job_class=@MTEBJob
PEFTTrain.model_path='EleutherAI/pythia-70m'
PEFTTrain.tokenizer_path='EleutherAI/pythia-70m'
PEFTTrain.tau=40
PEFTTrain.training_steps=1000
PEFTTrain.batch_size=1024
PEFTTrain.checkpoint_freq=100
PEFTTrain.peft_config_class = @peft.LoraConfig
    LoraConfig.r=32
    LoraConfig.target_modules=['query_key_value', 'dense', 'dense_h_to_4h', 'embed_in', 'dense_4h_to_h']
